{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Keras\n",
    "\n",
    "Doc [here](https://www.tensorflow.org/guide/keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/default/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, \n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
    "model.add(layers.Dense(64, \n",
    "                       activation='sigmoid',\n",
    "                       bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(32,\n",
    "                       kernel_initializer='orthogonal',\n",
    "                       bias_initializer=tf.keras.initializers.constant(2.0)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/default/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 699us/sample - loss: 18.0976 - acc: 0.0920\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 13.5388 - acc: 0.0330\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 13.0527 - acc: 0.1090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0471f3b860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,1))\n",
    "\n",
    "model.fit(data,\n",
    "          labels,\n",
    "          epochs=3,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 0s 262us/sample - loss: 12.7066 - acc: 0.1000 - val_loss: 12.7606 - val_acc: 0.0400\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 138us/sample - loss: 12.3861 - acc: 0.0850 - val_loss: 12.4604 - val_acc: 0.0800\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 12.1160 - acc: 0.0840 - val_loss: 12.2219 - val_acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0470149710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "val_data = np.random.random((100,32))\n",
    "val_labels = np.random.random((100,10))\n",
    "\n",
    "model.fit(data,\n",
    "          labels,\n",
    "          epochs=3,\n",
    "          batch_size=32,\n",
    "          validation_data=(val_data,\n",
    "                           val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variations on that\n",
    "\n",
    "For instance, it is possible to define the model in one go, as an array of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 568us/sample - loss: 11.5368 - acc: 0.0920 - val_loss: 11.7015 - val_acc: 0.0800\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 148us/sample - loss: 11.4609 - acc: 0.1030 - val_loss: 11.6988 - val_acc: 0.1100\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 11.4558 - acc: 0.1140 - val_loss: 11.6984 - val_acc: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f045c321e80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adagrad(), # why not this one\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# reusing the same dummy data\n",
    "model2.fit(data,labels,epochs=3,batch_size=53,\n",
    "           validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/default/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 671us/sample - loss: 0.2403 - mean_absolute_error: 0.4071 - val_loss: 0.2517 - val_mean_absolute_error: 0.4171\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.2402 - mean_absolute_error: 0.4071 - val_loss: 0.2516 - val_mean_absolute_error: 0.4172\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.2401 - mean_absolute_error: 0.4070 - val_loss: 0.2515 - val_mean_absolute_error: 0.4170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0468063518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can just recompile it with another optimizer\n",
    "model2.compile(optimizer=tf.train.AdamOptimizer(0.001), # why not this one\n",
    "               loss='mse',\n",
    "               metrics=['mae'])\n",
    "\n",
    "# reusing the same dummy data\n",
    "model2.fit(data,labels,epochs=3,batch_size=53,\n",
    "           validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 877us/sample - loss: 11.4908 - categorical_accuracy: 0.1310 - val_loss: 12.0605 - val_categorical_accuracy: 0.1200\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 250us/sample - loss: 11.5362 - categorical_accuracy: 0.1010 - val_loss: 11.7051 - val_categorical_accuracy: 0.0800\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 480us/sample - loss: 11.4570 - categorical_accuracy: 0.1020 - val_loss: 11.6884 - val_categorical_accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f045c23de48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and yet another\n",
    "model2.compile(optimizer=tf.train.RMSPropOptimizer(0.01), # why not this one\n",
    "               loss=tf.keras.losses.categorical_crossentropy,\n",
    "               metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "\n",
    "# reusing the same dummy data\n",
    "model2.fit(data,labels,epochs=3,batch_size=12,\n",
    "           validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 11.6093 - acc: 0.0984\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11.5074 - acc: 0.0921\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11.5151 - acc: 0.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04178bc8d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ds = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "keras_ds = keras_ds.batch(32)\n",
    "keras_ds = keras_ds.repeat()\n",
    "\n",
    "model.fit(keras_ds,\n",
    "          epochs=3,\n",
    "          steps_per_epoch=50) # why do we need to specify this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the doc:\n",
    "\n",
    "> Here, the fit method uses the steps_per_epoch argument—this is the number of training steps the model runs before it moves to the next epoch. Since the Dataset yields batches of data, this snippet does not require a batch_size.\n",
    "\n",
    "With validation now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 11.4831 - acc: 0.0975 - val_loss: 11.7040 - val_acc: 0.0833\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 11.4932 - acc: 0.1049 - val_loss: 11.5457 - val_acc: 0.0735\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 11.4786 - acc: 0.1065 - val_loss: 11.6119 - val_acc: 0.0588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0415e420f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ds = tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "keras_ds = keras_ds.batch(32).repeat()\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_data,val_labels))\n",
    "val_ds = val_ds.batch(32).repeat()\n",
    "\n",
    "model.fit(keras_ds,\n",
    "          epochs=3,\n",
    "          steps_per_epoch=100,\n",
    "          validation_data=val_ds,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 223us/sample - loss: 11.4643 - acc: 0.1130\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 11.4741 - acc: 0.1180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.474053680896759, 0.118]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_d = np.random.random((1000,32))\n",
    "eval_l = np.random.random((1000,10))\n",
    "\n",
    "model.evaluate(eval_d, \n",
    "               eval_l, \n",
    "               batch_size=32)\n",
    "model.evaluate(keras_ds, steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(eval_d, batch_size=64)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 586us/sample - loss: 11.5404 - acc: 0.0930\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 11.4977 - acc: 0.0830\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 11.4762 - acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04144bb4a8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing a model\n",
    "\n",
    "As usual, more modularity and fine-grained control comes at the cost of more potential mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.dense_1 = layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # needed to use subc model in a functional-style model\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 0s 452us/sample - loss: 11.4409 - acc: 0.1140\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 11.4406 - acc: 0.1200\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 11.4413 - acc: 0.1240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0400f4ae10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = MyModel(num_classes=10)\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    # necessary for serialization\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 0s 406us/sample - loss: 11.4835 - acc: 0.1000\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 85us/sample - loss: 11.4640 - acc: 0.0990\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.4579 - acc: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0400652240>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "model.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 11.4871 - acc: 0.1294 - val_loss: 11.7084 - val_acc: 0.0521\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 11.4410 - acc: 0.1250 - val_loss: 11.5548 - val_acc: 0.0735\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 11.4758 - acc: 0.1377 - val_loss: 11.6230 - val_acc: 0.0588\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 11.4753 - acc: 0.1482 - val_loss: 11.7142 - val_acc: 0.1029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03fbdeda90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "model.fit(keras_ds,epochs=5, # since from dataset, no batch\n",
    "          steps_per_epoch=50, # must be specified\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_ds,\n",
    "          validation_steps=3) # same as steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 11.5334 - acc: 0.1060\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 11.4909 - acc: 0.1060\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 11.4783 - acc: 0.1090\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 11.4696 - acc: 0.1160\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 11.4642 - acc: 0.1090\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(eval_d, eval_l, epochs=5, batch_size=32)\n",
    "\n",
    "model.save_weights('./dummy_keras/model')\n",
    "# # also possible as h5\n",
    "# model.save_weights('./dummy_keras/model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 11.4588 - acc: 0.1110\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 11.4554 - acc: 0.1290\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 11.4512 - acc: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03f73eb358>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./dummy_keras/model')\n",
    "# model.load_weights('./dummy_keras/model.h5')\n",
    "model.fit(eval_d, eval_l, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_15\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_43\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_44\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}\n",
      "\n",
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'batch_input_shape': [None, 32],\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_43',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_44',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_15'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "json_string = model.to_json()\n",
    "print(json_string)\n",
    "print()\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 11.5626 - acc: 0.1050\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 11.4918 - acc: 0.1230\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 11.4775 - acc: 0.1210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03f557c780>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible then to create a new model from it\n",
    "new_model = tf.keras.models.model_from_json(json_string)\n",
    "\n",
    "new_model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "new_model.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      batch_input_shape: !!python/tuple [null, 32]\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_43\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_44\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_15\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# same with yaml\n",
    "\n",
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 11.5587 - acc: 0.0930\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 215us/sample - loss: 11.5118 - acc: 0.0980\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 176us/sample - loss: 11.4910 - acc: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03f5138a20>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible then to create a new model from it\n",
    "new_model = tf.keras.models.model_from_yaml(yaml_string)\n",
    "\n",
    "new_model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "new_model.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 634us/sample - loss: 11.4352 - acc: 0.1420\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 181us/sample - loss: 11.4312 - acc: 0.1570\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 190us/sample - loss: 11.4289 - acc: 0.1570\n",
      "done training!\n",
      "------------------------------\n",
      "reloading model, training again:\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1s 600us/sample - loss: 11.4286 - acc: 0.1570\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 11.4246 - acc: 0.1640\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 11.4218 - acc: 0.1520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03f39189e8>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='tanh', input_shape=(32,)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(eval_d, eval_l, batch_size=32, epochs=3)\n",
    "print('done training!')\n",
    "print('-'*30)\n",
    "\n",
    "model.save('./dummy_keras/entire.h5')\n",
    "print('reloading model, training again:')\n",
    "model_loaded = tf.keras.models.load_model('./dummy_keras/entire.h5')\n",
    "model_loaded.fit(eval_d, eval_l, batch_size=32, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
