{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.GradientTape \n",
    "\n",
    "Documentation [here](https://www.tensorflow.org/api_docs/python/tf/GradientTape). \n",
    "\n",
    "A few experiments, mostly following the tf documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(5.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = x**2\n",
    "dy_dx = g.gradient(y,x) # should result in 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(dy_dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nestings possible in order to retrieve higher-order derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48.0, 24.0)\n",
      "[48.0, 24.0]\n",
      "{'a': 48.0, 'b': 24.0}\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(4.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    with tf.GradientTape() as gg:\n",
    "        gg.watch(x)\n",
    "        y = x**3\n",
    "    dy_dx = gg.gradient(y,x)  # 3*x^2 = 3*16 = 48\n",
    "d2y_dx2 = g.gradient(dy_dx,x) # 6*x = 6*4.0 = 24\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    print(sess.run((dy_dx, d2y_dx2))) # pass desired elements \n",
    "    print(sess.run([dy_dx, d2y_dx2])) # as tuple, list,\n",
    "    print(sess.run({'a':dy_dx,'b':d2y_dx2})) #  dict..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the [documentation](https://www.tensorflow.org/api_docs/python/tf/Session) states:\n",
    "> The `fetches` argument (first argument of `run`) may be a single graph element, or an arbitrarily nested list, tuple, namedtuple, dict, or OrderedDict containing graph elements at its leaves. \n",
    "\n",
    "---\n",
    "\n",
    "By default, resources held by `GradientTape` are accessible only once, unless `persistent=True` is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a77ed685a288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdz_dx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 4*x^3 for x = 2: 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdy_dx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \"\"\"\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[1;32m    912\u001b[0m                          \"non-persistent tapes.\")\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.0)\n",
    "with tf.GradientTape(persistent=False) as g:\n",
    "    g.watch(x)\n",
    "    y = x**2\n",
    "    z = y**2\n",
    "dz_dx = g.gradient(z,x) # 4*x^3 for x = 2: 32\n",
    "dy_dx = g.gradient(y,x) # 4\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run((dz_dx, dy_dx)))\n",
    "    print(sess.run((dz_dx, dy_dx))) # error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32.0, 4.0)\n",
      "(32.0, 4.0)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.0)\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(x)\n",
    "    y = x**2\n",
    "    z = y**2\n",
    "dz_dx = g.gradient(z,x) # 4*x^3 for x = 2: 32\n",
    "dy_dx = g.gradient(y,x) # 4\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run((dz_dx, dy_dx)))\n",
    "    print(sess.run((dz_dx, dy_dx))) # it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-grained control over variables disabling automatic tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "var_b variable is not being followed, hence error:\n",
      "Fetch argument None has invalid type <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "var_a = tf.constant(2.0)\n",
    "var_b = tf.constant(5.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True, \n",
    "                     watch_accessed_variables=False) as tape:\n",
    "    tape.watch(var_a)\n",
    "    y = var_a**2\n",
    "    z = var_b ** 3\n",
    "dy_da = tape.gradient(y, var_a)\n",
    "dz_db = tape.gradient(z, var_b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(dy_da))\n",
    "    try:\n",
    "        print(sess.run(dz_db)) # throws an error\n",
    "    except Exception as e:\n",
    "        print('var_b variable is not being followed, hence error:')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A note of warning when customizing models:\n",
    "> Note that when using models you should ensure that your variables exist when using `watch_accessed_variables=False`. Otherwise it's quite easy to make your first iteration not have any gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.921738    5.2549005  -3.4237587   1.0484527  -2.1596549   7.2284975\n",
      "  -8.753367    2.309942    2.626636    2.2715087   2.1964502  -0.43788818\n",
      "   0.9118432  -1.8459383   4.7647614  -2.135406    0.27540636 10.666039\n",
      "  -5.8266163  -0.13711858  2.7537673  -8.153975    0.37899143 -3.478874\n",
      "   0.4156808  -2.409906   -3.4665046  -0.5386368   0.56853664  1.9909041\n",
      "  -0.2896165   1.9271399 ]]\n",
      "\n",
      "Nope! Error:\n",
      "Fetch argument None has invalid type <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.layers.Dense(32)\n",
    "b = tf.keras.layers.Dense(32)\n",
    "inputs = tf.constant([[float(x) for x in range(10)]])\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:   \n",
    "    tape.watch(a.variables) # `a.build` hasn't been called yet\n",
    "                            # therefore `a.variables` will be empty\n",
    "    result = b(a(inputs))\n",
    "    g = tape.gradient(result, a.variables)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(result))\n",
    "    print()\n",
    "    try:\n",
    "        print(sess.run(g))\n",
    "    except Exception as e:\n",
    "        print('Nope! Error:')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better with calling `build(input_shape)` beforehand. [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense#build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -8.556849     4.9956393   -5.173847     1.3807405    4.371144\n",
      "   -4.902327     2.1342604   -1.0151781   -2.6916428   -0.29353797\n",
      "    6.632813     4.823284     5.929711    -2.022577     3.9823647\n",
      "    1.5416613   -2.032748     1.2983477    0.42888513  -2.187703\n",
      "  -10.97552     -1.0283854    2.004771    -2.4335957    4.043797\n",
      "    4.5529833    1.2305776   -3.1239045    2.3101783    2.6177657\n",
      "   -1.1685332   -5.174881  ]]\n",
      "------------------------------\n",
      "[(10, 32), (32,)]\n",
      "[array([[ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
      "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
      "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
      "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "        -0.00000000e+00, -0.00000000e+00],\n",
      "       [ 1.21239734e+00, -4.05450672e-01,  1.08334661e+00,\n",
      "         7.42777646e-01,  1.35345089e+00, -7.37994134e-01,\n",
      "        -3.96945179e-01,  1.96774495e+00, -1.95854139e+00,\n",
      "        -8.12884927e-01,  6.56954229e-01, -2.97190130e-01,\n",
      "         4.08002913e-01,  1.20953768e-01,  5.44926107e-01,\n",
      "        -8.33649039e-01, -1.49100363e-01,  1.07986510e-01,\n",
      "        -2.48243904e+00,  1.16151476e+00,  6.36494160e-03,\n",
      "        -1.17755365e+00, -2.11942166e-01,  4.09151524e-01,\n",
      "        -3.84340286e-02, -5.92947364e-01, -4.13943619e-01,\n",
      "        -1.39868319e+00,  1.36176914e-01, -8.35776389e-01,\n",
      "        -3.31851125e-01, -5.59103191e-01],\n",
      "       [ 2.42479467e+00, -8.10901344e-01,  2.16669321e+00,\n",
      "         1.48555529e+00,  2.70690179e+00, -1.47598827e+00,\n",
      "        -7.93890357e-01,  3.93548989e+00, -3.91708279e+00,\n",
      "        -1.62576985e+00,  1.31390846e+00, -5.94380260e-01,\n",
      "         8.16005826e-01,  2.41907537e-01,  1.08985221e+00,\n",
      "        -1.66729808e+00, -2.98200727e-01,  2.15973020e-01,\n",
      "        -4.96487808e+00,  2.32302952e+00,  1.27298832e-02,\n",
      "        -2.35510731e+00, -4.23884332e-01,  8.18303049e-01,\n",
      "        -7.68680573e-02, -1.18589473e+00, -8.27887237e-01,\n",
      "        -2.79736638e+00,  2.72353828e-01, -1.67155278e+00,\n",
      "        -6.63702250e-01, -1.11820638e+00],\n",
      "       [ 3.63719201e+00, -1.21635199e+00,  3.25003982e+00,\n",
      "         2.22833300e+00,  4.06035280e+00, -2.21398234e+00,\n",
      "        -1.19083548e+00,  5.90323496e+00, -5.87562418e+00,\n",
      "        -2.43865490e+00,  1.97086263e+00, -8.91570389e-01,\n",
      "         1.22400880e+00,  3.62861305e-01,  1.63477826e+00,\n",
      "        -2.50094700e+00, -4.47301090e-01,  3.23959529e-01,\n",
      "        -7.44731712e+00,  3.48454428e+00,  1.90948248e-02,\n",
      "        -3.53266096e+00, -6.35826468e-01,  1.22745454e+00,\n",
      "        -1.15302086e-01, -1.77884209e+00, -1.24183083e+00,\n",
      "        -4.19604969e+00,  4.08530742e-01, -2.50732923e+00,\n",
      "        -9.95553374e-01, -1.67730951e+00],\n",
      "       [ 4.84958935e+00, -1.62180269e+00,  4.33338642e+00,\n",
      "         2.97111058e+00,  5.41380358e+00, -2.95197654e+00,\n",
      "        -1.58778071e+00,  7.87097979e+00, -7.83416557e+00,\n",
      "        -3.25153971e+00,  2.62781692e+00, -1.18876052e+00,\n",
      "         1.63201165e+00,  4.83815074e-01,  2.17970443e+00,\n",
      "        -3.33459616e+00, -5.96401453e-01,  4.31946039e-01,\n",
      "        -9.92975616e+00,  4.64605904e+00,  2.54597664e-02,\n",
      "        -4.71021461e+00, -8.47768664e-01,  1.63660610e+00,\n",
      "        -1.53736115e-01, -2.37178946e+00, -1.65577447e+00,\n",
      "        -5.59473276e+00,  5.44707656e-01, -3.34310555e+00,\n",
      "        -1.32740450e+00, -2.23641276e+00],\n",
      "       [ 6.06198692e+00, -2.02725339e+00,  5.41673279e+00,\n",
      "         3.71388817e+00,  6.76725435e+00, -3.68997073e+00,\n",
      "        -1.98472595e+00,  9.83872509e+00, -9.79270744e+00,\n",
      "        -4.06442451e+00,  3.28477120e+00, -1.48595071e+00,\n",
      "         2.04001451e+00,  6.04768872e-01,  2.72463059e+00,\n",
      "        -4.16824532e+00, -7.45501816e-01,  5.39932549e-01,\n",
      "        -1.24121952e+01,  5.80757380e+00,  3.18247080e-02,\n",
      "        -5.88776827e+00, -1.05971086e+00,  2.04575753e+00,\n",
      "        -1.92170143e-01, -2.96473694e+00, -2.06971812e+00,\n",
      "        -6.99341583e+00,  6.80884600e-01, -4.17888212e+00,\n",
      "        -1.65925562e+00, -2.79551601e+00],\n",
      "       [ 7.27438402e+00, -2.43270397e+00,  6.50007963e+00,\n",
      "         4.45666599e+00,  8.12070560e+00, -4.42796469e+00,\n",
      "        -2.38167095e+00,  1.18064699e+01, -1.17512484e+01,\n",
      "        -4.87730980e+00,  3.94172525e+00, -1.78314078e+00,\n",
      "         2.44801760e+00,  7.25722611e-01,  3.26955652e+00,\n",
      "        -5.00189400e+00, -8.94602180e-01,  6.47919059e-01,\n",
      "        -1.48946342e+01,  6.96908855e+00,  3.81896496e-02,\n",
      "        -7.06532192e+00, -1.27165294e+00,  2.45490909e+00,\n",
      "        -2.30604172e-01, -3.55768418e+00, -2.48366165e+00,\n",
      "        -8.39209938e+00,  8.17061484e-01, -5.01465845e+00,\n",
      "        -1.99110675e+00, -3.35461903e+00],\n",
      "       [ 8.48678112e+00, -2.83815479e+00,  7.58342648e+00,\n",
      "         5.19944334e+00,  9.47415638e+00, -5.16595888e+00,\n",
      "        -2.77861619e+00,  1.37742147e+01, -1.37097893e+01,\n",
      "        -5.69019461e+00,  4.59867954e+00, -2.08033085e+00,\n",
      "         2.85602045e+00,  8.46676350e-01,  3.81448269e+00,\n",
      "        -5.83554316e+00, -1.04370260e+00,  7.55905569e-01,\n",
      "        -1.73770733e+01,  8.13060379e+00,  4.45545912e-02,\n",
      "        -8.24287605e+00, -1.48359513e+00,  2.86406064e+00,\n",
      "        -2.69038200e-01, -4.15063143e+00, -2.89760542e+00,\n",
      "        -9.79078197e+00,  9.53238368e-01, -5.85043478e+00,\n",
      "        -2.32295799e+00, -3.91372228e+00],\n",
      "       [ 9.69917870e+00, -3.24360538e+00,  8.66677284e+00,\n",
      "         5.94222116e+00,  1.08276072e+01, -5.90395308e+00,\n",
      "        -3.17556143e+00,  1.57419596e+01, -1.56683311e+01,\n",
      "        -6.50307941e+00,  5.25563383e+00, -2.37752104e+00,\n",
      "         3.26402330e+00,  9.67630148e-01,  4.35940886e+00,\n",
      "        -6.66919231e+00, -1.19280291e+00,  8.63892078e-01,\n",
      "        -1.98595123e+01,  9.29211807e+00,  5.09195328e-02,\n",
      "        -9.42042923e+00, -1.69553733e+00,  3.27321219e+00,\n",
      "        -3.07472229e-01, -4.74357891e+00, -3.31154895e+00,\n",
      "        -1.11894655e+01,  1.08941531e+00, -6.68621111e+00,\n",
      "        -2.65480900e+00, -4.47282553e+00],\n",
      "       [ 1.09115763e+01, -3.64905596e+00,  9.75011921e+00,\n",
      "         6.68499899e+00,  1.21810579e+01, -6.64194727e+00,\n",
      "        -3.57250667e+00,  1.77097054e+01, -1.76268730e+01,\n",
      "        -7.31596422e+00,  5.91258812e+00, -2.67471123e+00,\n",
      "         3.67202616e+00,  1.08858395e+00,  4.90433502e+00,\n",
      "        -7.50284147e+00, -1.34190321e+00,  9.71878588e-01,\n",
      "        -2.23419514e+01,  1.04536324e+01,  5.72844744e-02,\n",
      "        -1.05979824e+01, -1.90747952e+00,  3.68236375e+00,\n",
      "        -3.45906258e-01, -5.33652639e+00, -3.72549248e+00,\n",
      "        -1.25881491e+01,  1.22559226e+00, -7.52198744e+00,\n",
      "        -2.98666000e+00, -5.03192854e+00]], dtype=float32), array([ 1.2123973 , -0.40545067,  1.0833466 ,  0.74277765,  1.3534509 ,\n",
      "       -0.73799413, -0.39694518,  1.967745  , -1.9585414 , -0.8128849 ,\n",
      "        0.6569542 , -0.29719013,  0.4080029 ,  0.12095377,  0.5449261 ,\n",
      "       -0.83364904, -0.14910036,  0.10798651, -2.482439  ,  1.1615148 ,\n",
      "        0.00636494, -1.1775537 , -0.21194217,  0.40915152, -0.03843403,\n",
      "       -0.59294736, -0.41394362, -1.3986832 ,  0.13617691, -0.8357764 ,\n",
      "       -0.33185112, -0.5591032 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "a2 = tf.keras.layers.Dense(32)\n",
    "b2 = tf.keras.layers.Dense(32)\n",
    "inputs2 = tf.constant([[float(x) for x in range(10)]])\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:   \n",
    "    a2.build(inputs2.shape)\n",
    "    tape.watch(a2.variables)                         \n",
    "    result2 = b2(a2(inputs2))\n",
    "    gg = tape.gradient(result2, a2.variables)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(result2))\n",
    "    print('-'*30)\n",
    "    \n",
    "    grads = sess.run(gg)    \n",
    "    print([grad.shape for grad in grads])\n",
    "    print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The [Jacobian](https://www.tensorflow.org/api_docs/python/tf/GradientTape) (the [square-shaped first-order partial derivatives of a vector-valued function](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)) can be computed manually, and also [as a batch](https://www.tensorflow.org/api_docs/python/tf/GradientTape#batch_jacobian), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5838531 3.0100074]\n",
      "\n",
      "Grad & Jac for x:\n",
      "[2. 4.]\n",
      "[[2. 0.]\n",
      " [0. 4.]]\n",
      "\n",
      "Grad & Jac for z:\n",
      "[-0.9092974 -0.14112  ]\n",
      "[[-0.9092974 -0.       ]\n",
      " [-0.        -0.14112  ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1.,2.]) \n",
    "z = tf.constant([2.,3.])\n",
    "\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(x)     \n",
    "    g.watch(z)\n",
    "    y = x * x + tf.cos(z) \n",
    "    \n",
    "grad_x = g.gradient(y,x)\n",
    "jacobian_x = g.jacobian(y,x)\n",
    "grad_z = g.gradient(y,z)\n",
    "jacobian_z = g.jacobian(y,z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))\n",
    "    print()\n",
    "    print('Grad & Jac for x:', sess.run(grad_x), sess.run(jacobian_x), sep='\\n')\n",
    "    print()\n",
    "    print('Grad & Jac for z:', sess.run(grad_z), sess.run(jacobian_z), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.]\n",
      " [ 9. 16.]]\n",
      "------------------------------\n",
      "[[[2. 0.]\n",
      "  [0. 4.]]\n",
      "\n",
      " [[6. 0.]\n",
      "  [0. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32) \n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)     \n",
    "    y = x * x \n",
    "\n",
    "batch_jacobian = g.batch_jacobian(y, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))\n",
    "    print('-'*30)    \n",
    "    # batch_jacobian is [[[2, 0], \n",
    "    #                     [0, 4]], \n",
    "    #                   [[6, 0], \n",
    "    #                    [0, 8]]]\n",
    "    print(sess.run(batch_jacobian))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
